{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL= 'https://www.indeed.fi/jobs?q=&l=Helsinki'\n",
    "\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_title(soup):\n",
    "    jobs = []\n",
    "    for div in soup.find_all(name='div', attrs={'class':'row'}):\n",
    "        for a in div.find_all(name='a', attrs={'data-tn-element':'jobTitle'}):\n",
    "            jobs.append(a['title'])\n",
    "    return (jobs)\n",
    "\n",
    "job_title(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def company_name(soup):\n",
    "    companies = []\n",
    "    for div in soup.find_all(name='div', attrs={'class':'row'}):\n",
    "        company = div.find_all(name='span', attrs={'class':'company'})\n",
    "        if len(company) > 0:\n",
    "            for b in company:\n",
    "                companies.append(b.text.strip())\n",
    "        else:\n",
    "            sec_try = div.find_all(name='span', attrs={'class':'result-link-source'})\n",
    "            for span in sec_try:\n",
    "                companies.append(span.text.strip())\n",
    "    return (companies)\n",
    "\n",
    "company_name(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location(soup):\n",
    "    locations = []\n",
    "    spans = soup.findAll('span', attrs={'class':'location'})\n",
    "    for span in spans:\n",
    "        locations.append(span.text.strip())\n",
    "    return (locations)\n",
    "\n",
    "location(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salary(soup):\n",
    "    salaries = []\n",
    "    for div in soup.findAll('div', attrs={'class':'row'}):\n",
    "        try:\n",
    "            salaries.append(div.find('nobr').text)\n",
    "        except:\n",
    "            try:\n",
    "                div_two = div.find(name='div', attrs={'class':'sjcl'})\n",
    "                div_three = div_two.find('div')\n",
    "                salaries.append(div_three.text.strip())\n",
    "            except:\n",
    "                salaries.append('Nothing_found')\n",
    "    return (salaries)\n",
    "\n",
    "salary(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_summary(soup):\n",
    "    summaries = []\n",
    "    \n",
    "    spans = soup.find_all(name='span', attrs={'class':'summary'})\n",
    "    for span in spans:\n",
    "        summaries.append(span.text.strip())\n",
    "    return (summaries)\n",
    "\n",
    "job_summary(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'http://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0DtHlbVmCuoMGCH-otvTazhiD-5Gp7bEjjE9EkCwGU0SRDO3uUKX07EXEdL12zkpbxmfpAc65WY-dpnenMiCneL4QpyqY9r8QVq4sNTRF5f5aS244hWDrDLZ1Bb_RVITRP4VmBJE8HvZFrHPBrvUdQzOre_0SxLWJJyOVpYNFELRSamKaCS7dBsZ_cZYmTRY4K87F4Gj0_qFbarhBTb8qse4VtmsgcpBY5gK55NTGr7wAaLfZ2nJA842WMOPjsIbfrz5e42BwsMrD0AHb4ZpgQJuMwEYeJ73PUxtDG8LmoMqcxoeFWiAM3tF4BQcbeopR-N61ii0pF0aW3gPLNxFkoem-p7I7sCI939W7vtc3j6Wzll1hvrUfKoxWemGUngiW5BuIW-5EoYqJhEBKrvydzw9d_c7ZCqivXaJbLzJwUngyDTdmg7bJMU-ZJhUKukIm0=&vjs=3&p=1&sk=&fvj=1',\n",
       " u'http://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0Dr5X7gwn7SfSqxLTIffrtMgTwDFH0yl8fMAdgkb9ALQDPF_NQ0Zvgw8LrJe3nF6FNjJPWTWA6LpSFx2prf3cdF0cBGdub4bEl36TclY8W2yP_ZcU-s67rcnP-SziaRpENPisXmCSs7DmwPDfh9LXqDfH5pUg4s1HtePGYsoAUqUioLGQgTUo9ZozNQ5bLjNbI_gZcQN9GEN-PfjV3ma1LagRkyhbj5f1d2IjcXZ1Dez4wIcmmxOHi0mSUK052VSHTAK2Wcm_CdLDfzPEYX_smCj33YOLgBPSwOwU7uieZEaLQfy3fiQ7NE7Gb1A6njnLV5xyyC5YRaHjEkgUapzHXaxTdVuIGnEmpaP4e0McdHiqvcy5XmmcswmDVVzwtVCa8AsKOEVOu6jHcrif1EF-YGzh03HgGlBe2yCCRzFy0TZn4Stwd4SAwLImAWL3fGnsiKhnM39h5yJqqj4mvgzRnMxpUby0cBKEvVXesvcXHOW8-J-uHeEzFOtz_aU_RRN6VKkMDR6ogzxAlRPW7XFVZC2Oco1oG1qb2fhgDp2tsJSFOJa1Nm2_oMpatRoDEzveKBGW6n3FQUKYktWAr6CTAiwOBaqYeRt5f8MEHiw10rYt96QvVIyF0y-uaJOITtKvryZIujAcihrTqa8yEtv_H0Lr6dZKzVIa87PG9NTYSFPw==&vjs=3&p=2&sk=&fvj=0',\n",
       " u'http://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0DtHlbVmCuoMGCH-otvTazhiD-5Gp7bEjjE9EkCwGU0SRDO3uUKX07Evkzxl7TTlCS1GaPHBssBk0j63p0O28lzvjMfZpXn4AMg1-_7uGoM4Ym9kwCxknxZGVFh3kNWt8HM_X96GEHJeTV71Yhnkibq1vKmkTL8_99NXoCWDFeO1QQCP550ZeWt61JEJOLuQvFPWYmNN85a5bdsEBV8_OduxOT2Bdd9l0Dzs6VkGFhdjUXAP2Kc-8AW18loQBBJfiTPQYRJJIi4ZHKokgYghbVLXKh0-5MFdLnMakF8UzYceifflpYYQh2xB2806UkNkhMwbRTh9XNef4JsFev_TuqMCJcYc-0dxnpPxeHV2Fl5zSQspIrIVeT1FwIA7HSpS6jIW9I03gZWEB1s9Z0S-y96eiI7B3vFJQeGn4ZPcHdYzw==&vjs=3&p=3&sk=&fvj=1',\n",
       " u'http://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0DGXSQnpA8fsWBLhO7KSAvtv_18vse61ipytCq1PORmhD8ZJe9HXiBglXlKw_aJyXm3dmIKNPrkt9sGPoh02yzZgmgawLO2X7iOHOcZzlp765F1Lf9wW4HVzdmtJNLdL1xKxEH6oUVlFjVLWk9qNWPzMB1OaYNuajHUDVk2BFvf_Y4O__fIFtTA0c5YBZi_ShPPfOQSK95rn_2hKt0VVb-7468wqXZgje707Eke53hBzJ3bnnK2MtAXVY0D8ax7BO5Wt2DnLzvVjA9LqnGfYblDSY08tz9oNkm4nMTPWtKt5-a5Y69g1YMSRBOc7vaAOF2CnkhqRGvf_N1h2q5KFw-9bOkt4WSWVT5Yn0vrwUViYXVBN40dAkWsFwhK0OTuddlQy4W6hJlawv3kKWltguaigoimYZBsUoo9CMB8u2-dwy43jVDIKzW1AvkS-AzxybUec_JAzManzSBx71BALG-beYrdXWy6j9ip5_7kXIFS0QNd09VooSR2cQH_A4Y_O4dg2vqoab0ZVdedTubj0EEpJaj4dFACFehnbbqAmHdoxiorNZc5yMnlvaHYICcz7Sr9FKJthTiikqoaJHp2wO1Rt8-4sxDlqiNgWCmr-nNN7Mz04YDmi4XZ&vjs=3&p=4&sk=&fvj=0',\n",
       " u'http://www.indeed.com/company/Vemgoo/jobs/Months-Internship-Adventure-Travel-Startup-Cape-Town-2d85c2c83c7e3bb0?fccid=56491bdca9aa27b4&vjs=3',\n",
       " u'http://www.indeed.com/rc/clk?jk=744a2c20cc9aab4d&fccid=97b08bb2448f2ab8&vjs=3',\n",
       " u'http://www.indeed.com/rc/clk?jk=6de7d8e1c2e77df6&fccid=1293d073937972a6&vjs=3',\n",
       " u'http://www.indeed.com/rc/clk?jk=20ee7b4f28ad1492&fccid=d56baf8d322ea311&vjs=3',\n",
       " u'http://www.indeed.com/rc/clk?jk=9a988d529e350030&fccid=df9d0e68c6ccf0fe&vjs=3',\n",
       " u'http://www.indeed.com/rc/clk?jk=a743124e77606e52&fccid=df9d0e68c6ccf0fe&vjs=3',\n",
       " u'http://www.indeed.com/rc/clk?jk=4853d4cab934da75&fccid=7a418c04a0c2d307&vjs=3',\n",
       " u'http://www.indeed.com/rc/clk?jk=a4e82cc0f5882117&fccid=0389b020f641b0a5&vjs=3',\n",
       " u'http://www.indeed.com/rc/clk?jk=5c3e8bdda13be48f&fccid=de412c14988999e1&vjs=3',\n",
       " u'http://www.indeed.com/rc/clk?jk=f68d01023de62b59&fccid=a3753b4854218389&vjs=3',\n",
       " u'http://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0BKozJpT_yXUSc9eX5Y49FJvEeOvOcVY74FXWKFVTsYPesAQu9V8qfmJwHfMoCrXYfT7gbL4Q749jQMTZ2OokAdjnYTpZNlVYVv3uT_SZABTHcOhOdpEZ6IZr1D6NCWD9TS7sU6Jr_iO-4HY55pnfAOQGEDqUetkZd89OTTnHpi83t92-wfUhQMCglKfk_Kue9t5DwB-W__IIGg8u9k0ZpL4SxVQ5pTbp07kNu4qK9716t5kUefZ0fo-V8tn3lIwalZovfiztuiTiV1z7CMe08LWlTxYw0OU1t08stRG9IjKnde8YSQv6uwngdQKoxjDiWVRa7mVbJyJ6dIZvUs_gAXH7r8k6IBZThEBPHQePAm0BgpH3Q2C6c_zeVQFoGMVjFcJ9YohLrDsHInGRkWdBRw648leFkEiCSupOG47o2MGg==&vjs=3&p=5&sk=&fvj=1',\n",
       " u'http://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0Dr5X7gwn7SfSqxLTIffrtMgTwDFH0yl8fMAdgkb9ALQDPF_NQ0ZvgwDdgGmae8yLxb0hrmxYNQzu3lHSg75KUHP_USGFG_uYGaycKrgW-Ayn8hy5VJBWCYZCWyxPx9mOaoyHYH3Sk77aitSBXvDrN0S-L0r-eLksOMeQNJSAybGB7b4hXKRsgZpQtXQ3CYGGe6QhMnJ7GAZkAwLZx5GHe1p6fAAYBO_4tDN6L7GgkWqlvRSTeY0zh_AXd9JIFzwSoLkRmcsGkBMkgZWxmtFzvm6E1i84zHfHwzCvWvA0oTxj0ftdg_rmS81MWWJEeJ4jn4rvbmX33E7bAlTsLk6u_q49gVs9TFazBWKBipj9-qNF81LfVU2Hc9l4HD17jLoT85108H_H0e_m6fAghe5GgOz5TX0alsQlbMSp0W6pnqBiL4a1gI0velgTy_WcQbF7ymDmLWGiky8lM6CiC6ggaKiIgkdTC-iOXH8NBYmPiDPcjV06zr-ipAkykshJDerPeg1l2-vDjsaaSVtOVdzYZKPwjNWwruCzR2gmm2VpqFZ0j-cOkOpIOf_wJGcbKD5XEIgPHMo2IYZGEbRMfOccOAspItadKFyLHFSEkB9tcDHJ2ye7pIGsVUD_R-iMJ8Uwjr88GQow_m8XITJADZmV-_&vjs=3&p=6&sk=&fvj=0']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL= 'https://www.indeed.fi/jobs?q=&l=Helsinki'\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "def job_link(soup):\n",
    "    targetElements = soup.findAll('div', attrs={'class':'row'})\n",
    "    job_link = []\n",
    "    for elem in targetElements:\n",
    "        home_url = \"http://www.indeed.com\"\n",
    "        jobs_link = \"%s%s\" % (home_url,elem.find('a').attrs['href'])\n",
    "        job_link.append(jobs_link) \n",
    "    return (job_link)\n",
    "\n",
    "job_link(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_description (url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    job = pd.DataFrame()\n",
    "    job_title = soup.find('h3', attrs={'class':'jobsearch-JobInfoHeader-title'}).text.strip()\n",
    "    company = soup.find('h4', attrs={'class':'jobsearch-CompanyReview--heading'}).text.strip()\n",
    "    job_description = soup.find('div', attrs={'class':'jobsearch-JobComponent-description'}).getText()\n",
    "    job = job.append({'job_title': job_title, 'company':company, 'job_description':job_description}, ignore_index=True)\n",
    "    job.to_csv(\"job_description.csv\", encoding='utf-8')\n",
    "    return job\n",
    "job_description('http://indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0C-y3nPVTcVVIQYCDalq_0ZwvXIP-cKtNq3Q5aJsS20Z9x8e-ifIvOG1_iIfBO9-EcGmarDzRWBiBTrnZw4R9S-pjb1jDS17RIoY73xABOdKkROn-teT-h25pBXuyGBttfLH3dew83426pFZEV-jVHTYr6v3VlLBTHmpyqvKbIc35Y6xqeWH4YkopmLBVhlLk3K8hp8Q7Kx0CT3rT6YgKvPg1o2X7He1bNwczy38iuSKgxYDqUD5HsR6aYLLM1iZeCRyouy45hiA_7z9BVvRM9TD9ct-UE9gE2lSW3oL0FtfaHEMIOftsha-4Ti4rSDojczFZwBST2MDkYYDeUygBQznkPJ7Wm_udWH98_l63OXcjr6OGx2u0sXuo3gtE6TbyDBbBuCUk2lK-m2lz3Y_xIg5fBqVaeVtc-ttUfYnc24f-k1__2V9Jb2XgU6vj_B0FQMYWYbXGfLtJP79-BQ3uXTdvXdmRW5omX0vgv7Sdp9ovrG6CWNgoW0_B_GwjOH2merzbEHfJ_1Sl8m3qinlyr1zylIj8rHLPLscQjiwtx8zyN_QaToaG8lZZurnlQBIrOLt2lZn7CotlRASpU6YXkZC-UsxKqbY9God7936OAt4RKhNYM0vfueXVIFzpekxSVp6-x9F4Gypm4KQUrt-wQ-vEaNyN4hNAVCXGE1iA_RtGbzplhzKOs5tWFLx1bWRdE=&vjs=3&p=6&sk=&fvj=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In Vaisalas Weather and Environment business area, our forward-thinking team focuses on providing solutions to react on challenging weather or air quality conditions. We partner with our customers to help them make the most informed decisions whenever environmental insight matters. We are looking for an efficient Customer Service Coordinator to join Project and Customer Services (PCS) team in Weather Business Area. This position is fixed-term (parental-leave substitute) and located at Vaisala headquarters in Vantaa. PCS is a global team providing professional project management, project delivery and engineering knowhow to Vaisala's international customer deliveries. We have successfully completed projects in over 100 countries on all 7 continents. We are looking for energetic and service oriented person who gets things done and problems solved. Your key responsibilities include You responsibility is to ensure that we fulfill Service Contract commitments to our customers by making sure that scheduled preventive maintenance visits are done on time, express spare part shipments leave as requested and warranty issues are handled in a prompt manner. You support Project Engineers when they prepare for service and installation visits around the world, helping them to order needed parts and tools for the trip. You also handle sales orders and financial transactions for Service activities. Part of your work will be coordinating customer visits to Vaisala for factory training and factory acceptance testing. You handle the practical arrangements for the visits and also help in hosting customers during their visits at the factory. In this role , you work closely together with delivery teams, technical support and Sales. Who we are looking for As a Customer Service Coordiator, your work days are never the same! We are looking for a person with a flexible mindset and eagerness to learn. You enjoy working with with people from different cultures and have a positive customer service attitude. You have excellent communication skills, written and spoken, especially in English but also in Finnish. Our ideal candidate has education in business, for example BBA or equivalent. We value experience from international business environment. For additional information on the position, please contact Seija Mononen +358 40 647 7381, best available on August 29 10:00-11:00 and August 31 10:00-11:00. Please submit your application with CV and salary request by September 9th, 2018 by completing the online application form. \""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _remove_attrs(text):\n",
    "    lines = (line.strip() for line in text.splitlines()) # break into lines\n",
    "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \")) # break multi-headlines into a line each\n",
    "    \n",
    "    def chunk_space(chunk):\n",
    "        chunk_out = chunk + ' ' # Need to fix spacing issue\n",
    "        return chunk_out\n",
    "    \n",
    "    text = ''.join(chunk_space(chunk) for chunk in chunks if chunk).encode('utf-8') # Get rid of all blank lines and ends of line\n",
    "        \n",
    "        \n",
    "    # Now clean out all of the unicode junk (this line works great!!!)\n",
    "        \n",
    "    try:\n",
    "        text = text.decode('unicode_escape').encode('ascii', 'ignore') # Need this as some websites aren't formatted\n",
    "    except:                                                            # in a way that this works, can occasionally throw\n",
    "        return                                                         # an exception\n",
    "       \n",
    "    \n",
    "    \n",
    "    return text\n",
    "\n",
    "def job_post (url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    job = pd.DataFrame()\n",
    "    job_description = soup.find('div', attrs={'class':'jobsearch-JobComponent-description'}).text\n",
    "    job_description_clean = _remove_attrs(job_description)\n",
    "    return job_description_clean\n",
    "job_post('http://indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0C-y3nPVTcVVIQYCDalq_0ZwvXIP-cKtNq3Q5aJsS20Z9x8e-ifIvOG1_iIfBO9-EcGmarDzRWBiBTrnZw4R9S-pjb1jDS17RIoY73xABOdKkROn-teT-h25pBXuyGBttfLH3dew83426pFZEV-jVHTYr6v3VlLBTHmpyqvKbIc35Y6xqeWH4YkopmLBVhlLk3K8hp8Q7Kx0CT3rT6YgKvPg1o2X7He1bNwczy38iuSKgxYDqUD5HsR6aYLLM1iZeCRyouy45hiA_7z9BVvRM9TD9ct-UE9gE2lSW3oL0FtfaHEMIOftsha-4Ti4rSDojczFZwBST2MDkYYDeUygBQznkPJ7Wm_udWH98_l63OXcjr6OGx2u0sXuo3gtE6TbyDBbBuCUk2lK-m2lz3Y_xIg5fBqVaeVtc-ttUfYnc24f-k1__2V9Jb2XgU6vj_B0FQMYWYbXGfLtJP79-BQ3uXTdvXdmRW5omX0vgv7Sdp9ovrG6CWNgoW0_B_GwjOH2merzbEHfJ_1Sl8m3qinlyr1zylIj8rHLPLscQjiwtx8zyN_QaToaG8lZZurnlQBIrOLt2lZn7CotlRASpU6YXkZC-UsxKqbY9God7936OAt4RKhNYM0vfueXVIFzpekxSVp6-x9F4Gypm4KQUrt-wQ-vEaNyN4hNAVCXGE1iA_RtGbzplhzKOs5tWFLx1bWRdE=&vjs=3&p=6&sk=&fvj=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-f78879256e27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjob_URLS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mjob_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0msoup_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_page\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0msoup_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/toantran/anaconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/toantran/anaconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/toantran/anaconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 548\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/toantran/anaconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mhttp_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/toantran/anaconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/toantran/anaconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mhttp_error_302\u001b[0;34m(self, req, fp, code, msg, headers)\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[0mhttp_error_301\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_303\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_307\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_302\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/toantran/anaconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/toantran/anaconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 548\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/toantran/anaconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mhttp_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/toantran/anaconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/toantran/anaconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mhttp_error_302\u001b[0;34m(self, req, fp, code, msg, headers)\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[0mhttp_error_301\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_303\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_307\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_302\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/toantran/anaconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/toantran/anaconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 548\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/toantran/anaconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mhttp_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/toantran/anaconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/toantran/anaconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mhttp_error_302\u001b[0;34m(self, req, fp, code, msg, headers)\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[0mhttp_error_301\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_303\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_307\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_302\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/toantran/anaconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/toantran/anaconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 548\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/toantran/anaconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/toantran/anaconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/toantran/anaconda2/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_full_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(columns=['Title', 'Company', 'Location', 'URL', 'Summary', 'Job Description'])\n",
    "job_URLS = []\n",
    "'''\n",
    "def _remove_attrs(text):\n",
    "    lines = (line.strip() for line in text.splitlines()) # break into lines\n",
    "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \")) # break multi-headlines into a line each\n",
    "    \n",
    "    def chunk_space(chunk):\n",
    "        chunk_out = chunk + ' ' # Need to fix spacing issue\n",
    "        return chunk_out\n",
    "    \n",
    "    text = ''.join(chunk_space(chunk) for chunk in chunks if chunk).encode('utf-8') # Get rid of all blank lines and ends of line\n",
    "        \n",
    "        \n",
    "    # Now clean out all of the unicode junk (this line works great!!!)\n",
    "        \n",
    "    try:\n",
    "        text = text.decode('unicode_escape').encode('ascii', 'ignore') # Need this as some websites aren't formatted\n",
    "    except:                                                            # in a way that this works, can occasionally throw\n",
    "        return                                                         # an exception\n",
    "       \n",
    "    \n",
    "    \n",
    "    return text\n",
    "'''\n",
    "def job_post (url):\n",
    "    page = urllib2.urlopen(url).read()\n",
    "    soup_obj = BeautifulSoup(page, 'lxml')\n",
    "    soup = soup_obj.get_text()\n",
    "    job= soup.find('jobsearch-JobComponent-description')\n",
    "    #job = _remove_attrs(job_raw)\n",
    "    return job\n",
    "\n",
    "# Parse jobs in Helsinki\n",
    "\n",
    "for start in range(0, 100, 10):\n",
    "    page = requests.get('https://www.indeed.fi/jobs?q=&l=helsinki&start='+str(start))\n",
    "    time.sleep(1)  #ensuring at least 1 second between page grabs\n",
    "    soup = BeautifulSoup(page.text, \"lxml\", from_encoding=\"utf-8\")\n",
    "        \n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "            \n",
    "            #grabbing job title\n",
    "        for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "            jobs_link = \"%s%s\" % ('http://indeed.com',div.find('a').attrs['href'])\n",
    "            job_URLS.append(jobs_link)\n",
    "            title = a[\"title\"]\n",
    "                #grabbing company name\n",
    "            company = div.find_all(name='span', attrs={'class':'company'})\n",
    "            \n",
    "            if len(company) > 0:\n",
    "                for b in company:\n",
    "                    company = b.text.strip()\n",
    "            else:\n",
    "                sec_try = div.find_all(name=\"span\", attrs={\"class\":\"result-link-source\"})\n",
    "                for span in sec_try:\n",
    "                    company = span.text\n",
    "            \n",
    "            \n",
    "            #grabbing location name\n",
    "        c = div.findAll(\"span\", attrs={\"class\":\"location\"})\n",
    "        for span in c:\n",
    "            location = span.text\n",
    "            \n",
    "            \n",
    "            #grabbing summary text\n",
    "        d = div.findAll(\"span\", attrs={\"class\":\"summary\"})\n",
    "        for span in d:\n",
    "            summary = span.text.strip()\n",
    "                \n",
    "    for url in job_URLS:\n",
    "        job_page = urllib2.urlopen(url).read()\n",
    "        soup_obj = BeautifulSoup(job_page, 'lxml')\n",
    "        soup_job = soup_obj.get_text()\n",
    "        job_description= soup_job.find('jobsearch-JobComponent-description')\n",
    "         \n",
    "    df = df.append({'Title':title, 'Location':location, 'Company':company, 'URL':jobs_link , 'Summary':summary, 'Job Description':job_description}, ignore_index=True)\n",
    "        \n",
    "\n",
    "#saving sample_df as a local csv file — define your own local path to save contents \n",
    "df.to_csv(\"indeed_helsinki.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indeed Finland\n",
    "max_results_per_city = 500\n",
    "df = pd.DataFrame(columns=['City', 'Title', 'Company', 'Location', 'Summary', 'Salary' , 'URL'])\n",
    "city_set = ['Helsinki', 'Espoo', 'Oulu']\n",
    "\n",
    "for city in city_set:\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        page = requests.get('https://www.indeed.fi/jobs?q=&l='+str(city)+'&start='+str(start))\n",
    "        time.sleep(1)  #ensuring at least 1 second between page grabs\n",
    "        soup = BeautifulSoup(page.text, \"lxml\", from_encoding=\"utf-8\")\n",
    "        \n",
    "        for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        \n",
    "            #grabbing job title\n",
    "            for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "                jobs_link = \"%s%s\" % ('http://indeed.com',div.find('a').attrs['href'])\n",
    "                title = a[\"title\"]\n",
    "                #grabbing company name\n",
    "                company = div.find_all(name='span', attrs={'class':'company'})\n",
    "                if len(company) > 0:\n",
    "                    for b in company:\n",
    "                        company = b.text.strip()\n",
    "                else:\n",
    "                    sec_try = div.find_all(name=\"span\", attrs={\"class\":\"result-link-source\"})\n",
    "                    for span in sec_try:\n",
    "                        company = span.text\n",
    "            \n",
    "            \n",
    "            #grabbing location name\n",
    "            c = div.findAll(\"span\", attrs={\"class\":\"location\"})\n",
    "            for span in c:\n",
    "                location = span.text\n",
    "            \n",
    "            \n",
    "            #grabbing summary text\n",
    "            d = div.findAll(\"span\", attrs={\"class\":\"summary\"})\n",
    "            for span in d:\n",
    "                summary = span.text.strip()\n",
    "                \n",
    "         \n",
    "        df = df.append({'City':city, 'Title':title, 'Location':location, 'Company':company, 'URL':jobs_link , 'Summary':summary}, ignore_index=True)\n",
    "        \n",
    "\n",
    "#saving sample_df as a local csv file — define your own local path to save contents \n",
    "df.to_csv(\"indeed_finland.csv\", encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Indeed USA scrapper\n",
    "max_results_per_city = 1000\n",
    "city_set = ['Chicago', 'Austin', 'Seattle']\n",
    "df = pd.DataFrame(columns=['City', 'Title', 'Company', 'Location', 'Summary', 'Salary', 'URL'])\n",
    "\n",
    "for city in city_set:\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        page = requests.get('https://www.indeed.com/jobs?q=&l='+str(city)+'&start='+str(start))\n",
    "        time.sleep(1)  #ensuring at least 1 second between page grabs\n",
    "        soup = BeautifulSoup(page.text, \"lxml\", from_encoding=\"utf-8\")\n",
    "        \n",
    "        for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "            \n",
    "            #grabbing job title\n",
    "            for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "                jobs_link = \"%s%s\" % ('http://indeed.com',div.find('a').attrs['href'])\n",
    "                title = a[\"title\"]\n",
    "                #grabbing company name\n",
    "                company = div.find_all(name='span', attrs={'class':'company'})\n",
    "                if len(company) > 0:\n",
    "                    for b in company:\n",
    "                        company = b.text.strip()\n",
    "                else:\n",
    "                    sec_try = div.find_all(name=\"span\", attrs={\"class\":\"result-link-source\"})\n",
    "                    for span in sec_try:\n",
    "                        company = span.text\n",
    "            \n",
    "            \n",
    "            #grabbing location name\n",
    "            c = div.findAll(\"span\", attrs={\"class\":\"location\"})\n",
    "            for span in c:\n",
    "                location = span.text\n",
    "            \n",
    "            \n",
    "            #grabbing summary text\n",
    "            d = div.findAll(\"span\", attrs={\"class\":\"summary\"})\n",
    "            for span in d:\n",
    "                summary = span.text.strip()\n",
    "                \n",
    "                    \n",
    "            \n",
    "            df = df.append({'City':city, 'Title':title, 'Location':location, 'Company':company, 'URL':jobs_link, 'Summary':summary}, ignore_index=True)\n",
    "\n",
    "#saving sample_df as a local csv file — define your own local path to save contents \n",
    "df.to_csv(\"indeed_usa.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda2]",
   "language": "python",
   "name": "conda-env-anaconda2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
