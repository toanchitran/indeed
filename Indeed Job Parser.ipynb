{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract job list from search result page\n",
    "def parse(url):\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.content, 'html.parser', from_encoding=\"utf-8\")\n",
    "    df = pd.DataFrame(columns=[\"Title\",\"Location\",\"Company\",\"Salary\", \"Synopsis\"])\n",
    "    for each in soup.find_all(class_= \"result\" ):\n",
    "        try: \n",
    "            title = each.find(class_='jobtitle').text.replace('\\n', '')\n",
    "        except:\n",
    "            title = 'None'\n",
    "        try:\n",
    "            location = each.find('span', {'class':\"location\" }).text.replace('\\n', '')\n",
    "        except:\n",
    "            location = 'None'\n",
    "        try: \n",
    "            company = each.find(class_='company').text.replace('\\n', '')\n",
    "        except:\n",
    "            company = 'None'\n",
    "        try:\n",
    "            salary = each.find('span', {'class':'no-wrap'}).text\n",
    "        except:\n",
    "            salary = 'None'\n",
    "        try:\n",
    "            url = each.find('a').attrs['href']\n",
    "            job_url = 'htpp://indeed.com' + url\n",
    "        except:\n",
    "            job_url = 'http://indeed.com'\n",
    "        synopsis = each.find('span', {'class':'summary'}).text.replace('\\n', '')\n",
    "        df = df.append({'Title':title, 'Location':location, 'Company':company, 'URL':job_url ,'Salary':salary, 'Synopsis':synopsis}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jr Data Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Callière Group</td>\n",
       "      <td>None</td>\n",
       "      <td>Experience using some of the major...</td>\n",
       "      <td>htpp://indeed.com/rc/clk?jk=0875c173cf80e8c3&amp;f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY 10001 (Chelsea area)</td>\n",
       "      <td>Comcast</td>\n",
       "      <td>None</td>\n",
       "      <td>Freewheel is currently looking to ...</td>\n",
       "      <td>htpp://indeed.com/rc/clk?jk=c25dd7bf92018138&amp;f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist, Analytics</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Slack</td>\n",
       "      <td>None</td>\n",
       "      <td>You should have deep technical ski...</td>\n",
       "      <td>htpp://indeed.com/rc/clk?jk=3220345942a1625f&amp;f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Armonk, NY 10504</td>\n",
       "      <td>IBM</td>\n",
       "      <td>None</td>\n",
       "      <td>You will work alongside consultant...</td>\n",
       "      <td>htpp://indeed.com/rc/clk?jk=f41b0ee76cebe5f9&amp;f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Interactive Brokers</td>\n",
       "      <td>None</td>\n",
       "      <td>Interactive Brokers Group (IBG) is...</td>\n",
       "      <td>htpp://indeed.com/rc/clk?jk=1ff7ee9cdc7a8fec&amp;f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>HUMAN RIGHTS COMMISSION</td>\n",
       "      <td>\\n                $70,286 - $82,244 a year</td>\n",
       "      <td>Advise, as needed, on data governa...</td>\n",
       "      <td>htpp://indeed.com/rc/clk?jk=ce1824189e846b1a&amp;f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>Equityzen</td>\n",
       "      <td>None</td>\n",
       "      <td>3+ years of experience working wit...</td>\n",
       "      <td>htpp://indeed.com/rc/clk?jk=e642ed1c1bbb7bb3&amp;f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>None</td>\n",
       "      <td>The Innovation team is made up of ...</td>\n",
       "      <td>htpp://indeed.com/rc/clk?jk=b89c86bec775ae43&amp;f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Junior Data Analyst</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>compstak.com</td>\n",
       "      <td>None</td>\n",
       "      <td>Support and learn from our team of...</td>\n",
       "      <td>htpp://indeed.com/rc/clk?jk=97f36b381a02b201&amp;f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>NYC Administration for Children's Serv...</td>\n",
       "      <td>\\n                $70,286 - $83,784 a year</td>\n",
       "      <td>Support additional ad-hoc data req...</td>\n",
       "      <td>htpp://indeed.com/rc/clk?jk=4e3bb49c1c217e9c&amp;f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Title                           Location  \\\n",
       "0          Jr Data Scientist                       New York, NY   \n",
       "1             Data Scientist  New York, NY 10001 (Chelsea area)   \n",
       "2  Data Scientist, Analytics                       New York, NY   \n",
       "3      Data Scientist Intern                   Armonk, NY 10504   \n",
       "4      Junior Data Scientist                       New York, NY   \n",
       "5               Data Analyst                      Manhattan, NY   \n",
       "6             Data Scientist                      Manhattan, NY   \n",
       "7             Data Scientist                       New York, NY   \n",
       "8        Junior Data Analyst                       New York, NY   \n",
       "9               Data Analyst                      Manhattan, NY   \n",
       "\n",
       "                                             Company  \\\n",
       "0                                     Callière Group   \n",
       "1                                            Comcast   \n",
       "2                                              Slack   \n",
       "3                                                IBM   \n",
       "4                                Interactive Brokers   \n",
       "5                            HUMAN RIGHTS COMMISSION   \n",
       "6                                          Equityzen   \n",
       "7                                            Twitter   \n",
       "8                                       compstak.com   \n",
       "9          NYC Administration for Children's Serv...   \n",
       "\n",
       "                                       Salary  \\\n",
       "0                                        None   \n",
       "1                                        None   \n",
       "2                                        None   \n",
       "3                                        None   \n",
       "4                                        None   \n",
       "5  \\n                $70,286 - $82,244 a year   \n",
       "6                                        None   \n",
       "7                                        None   \n",
       "8                                        None   \n",
       "9  \\n                $70,286 - $83,784 a year   \n",
       "\n",
       "                                            Synopsis  \\\n",
       "0              Experience using some of the major...   \n",
       "1              Freewheel is currently looking to ...   \n",
       "2              You should have deep technical ski...   \n",
       "3              You will work alongside consultant...   \n",
       "4              Interactive Brokers Group (IBG) is...   \n",
       "5              Advise, as needed, on data governa...   \n",
       "6              3+ years of experience working wit...   \n",
       "7              The Innovation team is made up of ...   \n",
       "8              Support and learn from our team of...   \n",
       "9              Support additional ad-hoc data req...   \n",
       "\n",
       "                                                 URL  \n",
       "0  htpp://indeed.com/rc/clk?jk=0875c173cf80e8c3&f...  \n",
       "1  htpp://indeed.com/rc/clk?jk=c25dd7bf92018138&f...  \n",
       "2  htpp://indeed.com/rc/clk?jk=3220345942a1625f&f...  \n",
       "3  htpp://indeed.com/rc/clk?jk=f41b0ee76cebe5f9&f...  \n",
       "4  htpp://indeed.com/rc/clk?jk=1ff7ee9cdc7a8fec&f...  \n",
       "5  htpp://indeed.com/rc/clk?jk=ce1824189e846b1a&f...  \n",
       "6  htpp://indeed.com/rc/clk?jk=e642ed1c1bbb7bb3&f...  \n",
       "7  htpp://indeed.com/rc/clk?jk=b89c86bec775ae43&f...  \n",
       "8  htpp://indeed.com/rc/clk?jk=97f36b381a02b201&f...  \n",
       "9  htpp://indeed.com/rc/clk?jk=4e3bb49c1c217e9c&f...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse('http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def job_description_extraction(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    job = pd.DataFrame()\n",
    "    job_title = soup.find('h3', attrs={'class':'jobsearch-JobInfoHeader-title'}).getText()\n",
    "    company = soup.find('h4', attrs={'class':'jobsearch-CompanyReview--heading'}).getText()\n",
    "    job_description = soup.find('div', attrs={'class':'jobsearch-JobComponent-description'}).getText()\n",
    "    job = job.append({'job_title': job_title, 'company':company, 'job_description':job_description}, ignore_index=True)\n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Red Bull</td>\n",
       "      <td>Wings Team Member Helsinki\\nStudent Jobs\\nThe ...</td>\n",
       "      <td>Wings Team Member Helsinki</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    company                                    job_description  \\\n",
       "0  Red Bull  Wings Team Member Helsinki\\nStudent Jobs\\nThe ...   \n",
       "\n",
       "                    job_title  \n",
       "0  Wings Team Member Helsinki  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_description_extraction('https://www.indeed.com/viewjob?jk=eabfb767c41a478c&from=serp&vjs=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse jobs in Helsinki - v1\n",
    "for start in range(0, 50, 10):\n",
    "    page = requests.get('https://www.indeed.fi/jobs?q=&l=helsinki&start='+str(start))\n",
    "    time.sleep(0.1) #Ensuring at least 2 sec between page grabs\n",
    "    soup = BeautifulSoup(page.content, 'html.parser', from_encoding=\"utf-8\")\n",
    "        \n",
    "    df = pd.DataFrame(columns=[\"Title\",\"Location\",\"Company\",\"Salary\", \"Synopsis\"])\n",
    "    for each in soup.find_all(class_= \"result\" ):\n",
    "        try: \n",
    "            title = each.find(class_='jobtitle').text.replace('\\n', '')\n",
    "        except:\n",
    "            title = 'None'\n",
    "        try:\n",
    "            location = each.find('span', {'class':\"location\" }).text.replace('\\n', '')\n",
    "        except:\n",
    "            location = 'None'\n",
    "        try: \n",
    "            company = each.find(class_='company').text.replace('\\n', '')\n",
    "        except:\n",
    "            company = 'None'\n",
    "        try:\n",
    "            salary = each.find('span', {'class':'no-wrap'}).text\n",
    "        except:\n",
    "            salary = 'None'\n",
    "        try:\n",
    "            url = each.find('a').attrs['href']\n",
    "            job_url = 'http://indeed.com' + url\n",
    "        except:\n",
    "            job_url = 'http://indeed.com'\n",
    "        synopsis = each.find('span', {'class':'summary'}).text.replace('\\n', '')\n",
    "        df = df.append({'Title':title, 'Location':location, 'Company':company, 'URL':job_url ,'Salary':salary, 'Synopsis':synopsis}, ignore_index=True)\n",
    "\n",
    "df.to_csv('indeed_helsinki_1.csv', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:146: UserWarning: You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\n",
      "  warnings.warn(\"You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\")\n"
     ]
    }
   ],
   "source": [
    "# Parse jobs in Helsinki - v2\n",
    "\n",
    "df = pd.DataFrame(columns=['URL', 'Title', 'Company', 'Location', 'Summary', 'Salary'])\n",
    "\n",
    "for start in range(0, 50, 10):\n",
    "    page = requests.get('https://www.indeed.fi/jobs?q=&l=helsinki&start='+str(start))\n",
    "    time.sleep(1)  #ensuring at least 1 second between page grabs\n",
    "    soup = BeautifulSoup(page.text, \"lxml\", from_encoding=\"utf-8\")\n",
    "        \n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "            #creating an empty list to hold the data for each posting\n",
    "        job_post = []\n",
    "        num = (len(sample_df) + 1)\n",
    "            \n",
    "            \n",
    "            #grabbing job title\n",
    "        for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "            jobs_link = \"%s%s\" % ('http://indeed.com',div.find('a').attrs['href'])\n",
    "            title = a[\"title\"]\n",
    "                #grabbing company name\n",
    "            company = div.find_all(name='span', attrs={'class':'company'})\n",
    "            if len(company) > 0:\n",
    "                for b in company:\n",
    "                    company = b.text.strip()\n",
    "            else:\n",
    "                sec_try = div.find_all(name=\"span\", attrs={\"class\":\"result-link-source\"})\n",
    "                for span in sec_try:\n",
    "                    company = span.text\n",
    "            \n",
    "            \n",
    "            #grabbing location name\n",
    "        c = div.findAll(\"span\", attrs={\"class\":\"location\"})\n",
    "        for span in c:\n",
    "            location = span.text\n",
    "            \n",
    "            \n",
    "            #grabbing summary text\n",
    "        d = div.findAll(\"span\", attrs={\"class\":\"summary\"})\n",
    "        for span in d:\n",
    "            summary = span.text.strip()\n",
    "                \n",
    "                \n",
    "            #grabbing salary\n",
    "        try:\n",
    "            salary = div.find(\"nobr\").text\n",
    "        except:\n",
    "            try:\n",
    "                div_two = div.find(name=\"div\", attrs={\"class\":\"sjcl\"})\n",
    "                div_three = div_two.find(\"div\")\n",
    "                salary = div_three.text.strip()\n",
    "            except:\n",
    "                salary = \"Nothing_found\"\n",
    "         \n",
    "        df = df.append({'Title':title, 'Location':location, 'Company':company, 'URL':jobs_link ,'Salary':salary, 'Summary':summary}, ignore_index=True)\n",
    "        \n",
    "\n",
    "#saving sample_df as a local csv file — define your own local path to save contents \n",
    "df.to_csv(\"indeed_helsinki_2.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
